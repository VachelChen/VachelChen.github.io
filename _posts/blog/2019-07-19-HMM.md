---
layout: post
title: 隐马尔可夫模型的理解以及三个问题的解决
categories: HMM
description: 初次接触语音识别领域，第一大关就是隐马尔科夫模型，作为绝对的小白，这里记录了一些学习体会。
keywords: HMM
---

隐形马尔可夫模型，英文是 Hidden Markov Models，所以以下就简称 HMM。
既是马尔可夫模型，就一定存在马尔可夫链，该马尔可夫链服从马尔可夫性质：即无记忆性。也就是说，这一时刻的状态，受且只受前一时刻的影响，而不受更往前时刻的状态的影响。

先来看一个类似例子：

![HMMeg](/images/blog/HMMeg.png)

在这个马尔可夫模型中，存在三个状态，Sunny， Rainy， Cloudy，同时图片上标的是各个状态间的转移概率（图中箭头的权）。

这里我们主要先来了解一下其中的Elements。

###### 1.N(Number of states N)
这里的N表示状态数，放在上述例子就是Sunny， Rainy， Cloudy，而这些状态是隐式的、不可观测的（我们可以假想一个犯人在没有窗户的监狱里，他只能根据守卫的穿着猜测天气）。同时规定：t时刻的状态是qt。

###### 2.M(Model parameter M)
模型参数M是我们观测序列的数量，由上例子：

如果规定

```yaml
Sunny ————> 守卫穿短袖的概率大
Rainy ————> 守卫带伞的概率大
Cloudy————> 守卫穿棉衣的概率大
```
那么犯人所观测的守卫穿短袖、守卫带伞、守卫穿棉衣数量就是M。

###### 3.π (Initial state distribution π)
初始状态分布 π ，即我们考虑状态转移前最初的状态，也就是以上例子中的第一天会是什么天气。

![pai](/images/blog/pai.png)


###### 4.A (State transition probability distribution)
表示状态的转移可能分布。

![A](/images/blog/A.png)

表示t时刻状态为i，在t+1时刻状态为j的概率，也就是上例中比如第一天下雨第二天会是晴天的概率。

###### 5.B (Observation symbol probability distribution)
表示可观测信号可能分布。

![B](/images/blog/B.png)![bj](/images/blog/bj.png)


有了基础的认识结合实际例子来理解三个问题会好一点：
在这里，为了简化，把天气情况简单归结为晴天和雨天两种情况。雨天，她选择去散步，购物，收拾的概率分别是0.1，0.4，0.5， 而如果是晴天，她选择去散步，购物，收拾的概率分别是0.6，0.3，0.1。而天气的转换情况如下：这一天下雨，则下一天依然下雨的概率是0.7，而转换成晴天的概率是0.3；这一天是晴天，则下一天依然是晴天的概率是0.6，而转换成雨天的概率是0.4. 同时还存在一个初始概率，也就是第一天下雨的概率是0.6， 晴天的概率是0.4.

![HMMegeg](/images/blog/HMMegeg.png)


根据以上的信息，我们得到了 HMM的一些基本要素：初始概率分布 π，状态转移矩阵 A，观测量的概率分布 B，同时有两个状态，三种可能的观测值。

现在，重点是要了解并解决HMM 的三个问题。

· 问题1，已知整个模型，我女朋友告诉我，连续三天，她下班后做的事情分别是：散步，购物，收拾。那么，根据模型，计算产生这些行为的概率是多少。

· 问题2，同样知晓这个模型，同样是这三件事，我女朋友要我猜，这三天她下班后北京的天气是怎么样的。这三天怎么样的天气才最有可能让她做这样的事情。

· 问题3，最复杂的，我女朋友只告诉我这三天她分别做了这三件事，而其他什么信息我都没有。她要我建立一个模型，晴雨转换概率，第一天天气情况的概率分布，根据天气情况她选择做某事的概率分布。

## Three Basic Problems for Hidden Markov Models
#### Solution to Problem 1

